{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from en_gendata import *\n",
    "from loss_helper import FocalLoss\n",
    "from torch.nn import CrossEntropyLoss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0              EU\n",
      "1         rejects\n",
      "2          German\n",
      "3            call\n",
      "4              to\n",
      "           ...   \n",
      "203616      three\n",
      "203617    Swansea\n",
      "203618          1\n",
      "203619    Lincoln\n",
      "203620          2\n",
      "Name: Word, Length: 203621, dtype: object\n",
      "file dataset/EN/train.txt, tokens 203621\n",
      "0         SOCCER\n",
      "1              -\n",
      "2          JAPAN\n",
      "3            GET\n",
      "4          LUCKY\n",
      "          ...   \n",
      "46430    younger\n",
      "46431    brother\n",
      "46432          ,\n",
      "46433      Bobby\n",
      "46434          .\n",
      "Name: Word, Length: 46435, dtype: object\n",
      "file dataset/EN/test.txt, tokens 46435\n",
      "0               CRICKET\n",
      "1                     -\n",
      "2        LEICESTERSHIRE\n",
      "3                  TAKE\n",
      "4                  OVER\n",
      "              ...      \n",
      "51357                 .\n",
      "51358                --\n",
      "51359             Dhaka\n",
      "51360          Newsroom\n",
      "51361      880-2-506363\n",
      "Name: Word, Length: 51362, dtype: object\n",
      "file dataset/EN/valid.txt, tokens 51362\n"
     ]
    },
    {
     "data": {
      "text/plain": "             Sentence #     Word  Pos Chunk     Tag\n0           Sentence: 0       EU  NNP  B-NP   B-ORG\n1           Sentence: 0  rejects  VBZ  B-VP       O\n2           Sentence: 0   German   JJ  B-NP  B-MISC\n3           Sentence: 0     call   NN  I-NP       O\n4           Sentence: 0       to   TO  B-VP       O\n...                 ...      ...  ...   ...     ...\n203616  Sentence: 14040    three   CD  I-NP       O\n203617  Sentence: 14041  Swansea   NN  B-NP   B-ORG\n203618  Sentence: 14041        1   CD  I-NP       O\n203619  Sentence: 14041  Lincoln  NNP  I-NP   B-ORG\n203620  Sentence: 14041        2   CD  I-NP       O\n\n[203621 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence #</th>\n      <th>Word</th>\n      <th>Pos</th>\n      <th>Chunk</th>\n      <th>Tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sentence: 0</td>\n      <td>EU</td>\n      <td>NNP</td>\n      <td>B-NP</td>\n      <td>B-ORG</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sentence: 0</td>\n      <td>rejects</td>\n      <td>VBZ</td>\n      <td>B-VP</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Sentence: 0</td>\n      <td>German</td>\n      <td>JJ</td>\n      <td>B-NP</td>\n      <td>B-MISC</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Sentence: 0</td>\n      <td>call</td>\n      <td>NN</td>\n      <td>I-NP</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sentence: 0</td>\n      <td>to</td>\n      <td>TO</td>\n      <td>B-VP</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>203616</th>\n      <td>Sentence: 14040</td>\n      <td>three</td>\n      <td>CD</td>\n      <td>I-NP</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>203617</th>\n      <td>Sentence: 14041</td>\n      <td>Swansea</td>\n      <td>NN</td>\n      <td>B-NP</td>\n      <td>B-ORG</td>\n    </tr>\n    <tr>\n      <th>203618</th>\n      <td>Sentence: 14041</td>\n      <td>1</td>\n      <td>CD</td>\n      <td>I-NP</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>203619</th>\n      <td>Sentence: 14041</td>\n      <td>Lincoln</td>\n      <td>NNP</td>\n      <td>I-NP</td>\n      <td>B-ORG</td>\n    </tr>\n    <tr>\n      <th>203620</th>\n      <td>Sentence: 14041</td>\n      <td>2</td>\n      <td>CD</td>\n      <td>I-NP</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n<p>203621 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = 'dataset/EN/train.txt'\n",
    "data = read_from_file(train_dir)\n",
    "test_dir = 'dataset/EN/test.txt'\n",
    "test_data = read_from_file(test_dir)\n",
    "val_dir = 'dataset/EN/valid.txt'\n",
    "val_data = read_from_file(val_dir)\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "['B-ORG', 'O', 'B-MISC', 'B-PER', 'I-PER', 'B-LOC', 'I-ORG', 'I-MISC', 'I-LOC']"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.Tag.unique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "data.loc[data.Tag.str.contains('MISC'), 'Tag'] = 'O'\n",
    "list(data.Tag.unique())\n",
    "test_data.loc[test_data.Tag.str.contains('MISC'), 'Tag'] = 'O'\n",
    "val_data.loc[val_data.Tag.str.contains('MISC'), 'Tag'] = 'O'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "           Word    Tag\n0            EU  B-ORG\n1       rejects      O\n2        German      O\n3          call      O\n4            to      O\n...         ...    ...\n203616    three      O\n203617  Swansea  B-ORG\n203618        1      O\n203619  Lincoln  B-ORG\n203620        2      O\n\n[203621 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>EU</td>\n      <td>B-ORG</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>rejects</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>German</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>call</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>to</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>203616</th>\n      <td>three</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>203617</th>\n      <td>Swansea</td>\n      <td>B-ORG</td>\n    </tr>\n    <tr>\n      <th>203618</th>\n      <td>1</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>203619</th>\n      <td>Lincoln</td>\n      <td>B-ORG</td>\n    </tr>\n    <tr>\n      <th>203620</th>\n      <td>2</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n<p>203621 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data = val_data.iloc[:,[1,4]]\n",
    "test_data = test_data.iloc[:,[1,4]]\n",
    "data = data.iloc[:,[1,4]]\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "with open('dataset/EN/train1.txt', 'a') as f:\n",
    "    dfAsString = val_data.to_string(header=False, index=False)\n",
    "    f.write(dfAsString)\n",
    "# with open('dataset/EN/test1.txt', 'a') as f:\n",
    "#     dfAsString = test_data.to_string(header=False, index=False)\n",
    "#     f.write(dfAsString)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "with open('dataset/EN/vocab.txt', 'a') as f:\n",
    "    list = ((data1.Word.unique())).tolist()\n",
    "    f.writelines([\"%s\\n\" % item  for item in list])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(301418, 2) (203621, 2)\n"
     ]
    }
   ],
   "source": [
    "data1 = pd.concat([data, val_data, test_data])\n",
    "print(data1.shape,data.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "26883"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = ((data1.Word.unique())).tolist()\n",
    "len(l)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "        Word Tag\n24771   p.m.   O\n185670  p.m.   O\n196906  p.m.   O",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>24771</th>\n      <td>p.m.</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>185670</th>\n      <td>p.m.</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>196906</th>\n      <td>p.m.</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.loc[data1.Word=='p.m.',:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([False,  True,  True,  True,  True])"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.LongTensor([1,7,4,3,0])\n",
    "torch.logical_not(torch.eq(x, torch.tensor(1)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1136)\n",
      "tensor(1.9314)\n"
     ]
    }
   ],
   "source": [
    "logits = torch.rand(8, 7, 5) #8sentences , 5words, 7tags\n",
    "labels = torch.LongTensor([[0, 1, 1], [1, 2, 2], [2, 0, 1]])\n",
    "labels = torch.randint(0,7,(8,5))\n",
    "fl = FocalLoss(gamma=0, alpha=1)\n",
    "print(fl(logits, labels))\n",
    "loss_fct = CrossEntropyLoss()\n",
    "# seq_loss = loss_fct(logits.permute(0, 2, 1), labels)\n",
    "seq_loss = loss_fct(logits, labels)\n",
    "print(seq_loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2207, 7032, 3221, 2207, 5494, 4638, 1962, 3301, 1351]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# 使用bert的tokenizer将文字转化成数字。\n",
    "PRETRAINED_MODEL_NAME = \"bert-base-chinese\"  # 指定为中文\n",
    "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n",
    "clear_output()\n",
    "\n",
    "train_ids = []\n",
    "dev_ids = []\n",
    "test_ids = []\n",
    "for train_text in '小金是小肖的好朋友':\n",
    "  train_ids.append(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(train_text))[0])\n",
    "\n",
    "# for dev_text in dev_texts:\n",
    "#   dev_ids.append(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(dev_text)))\n",
    "#\n",
    "# for test_text in test_texts:\n",
    "#   test_ids.append(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(test_text)))\n",
    "\n",
    "print(train_ids)\n",
    "# print(dev_texts[66])\n",
    "# print(dev_labels[66])\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "bert = None\n",
    "print(bert==None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0+cu113\n",
      "11.3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Convulsions', 'Convulsions', 'ROOT')\n",
      "('occur', 'that', 'nsubj')\n",
      "('Convulsions', 'occur', 'relcl')\n",
      "('caused', 'after', 'mark')\n",
      "('caused', 'DTaP', 'nsubjpass')\n",
      "('caused', 'are', 'auxpass')\n",
      "('occur', 'caused', 'advcl')\n",
      "('caused', 'by', 'agent')\n",
      "('fever', 'a', 'det')\n",
      "('by', 'fever', 'pobj')\n",
      "('Convulsions', '.', 'punct')\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import networkx as nx\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(u'Convulsions that occur after DTaP are caused by a fever.')\n",
    "for token in doc:\n",
    "    print((token.head.text, token.text, token.dep_))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "PreTrainedTokenizer(name_or_path='bert-base-chinese', vocab_size=21128, model_max_len=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "20864"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "train_text = pickle.load(open('/home/xss/NER/BiLSTM/data3/dataset/CN/pickle/train_text.p', 'rb'))\n",
    "len(train_text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": "BertModel(\n  (embeddings): BertEmbeddings(\n    (word_embeddings): Embedding(21128, 768, padding_idx=0)\n    (position_embeddings): Embedding(512, 768)\n    (token_type_embeddings): Embedding(2, 768)\n    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (encoder): BertEncoder(\n    (layer): ModuleList(\n      (0): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (1): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (2): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (3): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (4): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (5): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (6): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (7): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (8): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (9): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (10): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (11): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n  )\n  (pooler): BertPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (activation): Tanh()\n  )\n)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer,BertModel\n",
    "bert = BertModel.from_pretrained('bert-base-chinese')\n",
    "bert"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "x = torch.arange(-5, 5, 0.1).view(-1, 1)\n",
    "y = -5 * x + 0.1 * torch.randn(x.size())\n",
    "\n",
    "model = torch.nn.Linear(1, 1)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.1)\n",
    "\n",
    "def train_model(iter):\n",
    "    for epoch in range(iter):\n",
    "        y1 = model(x)\n",
    "        loss = criterion(y1, y)\n",
    "        writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "train_model(10)\n",
    "writer.flush()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8421331761932822"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 0.775\n",
    "r = 0.922\n",
    "f1 = 2 * p * r / (p + r)\n",
    "f1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "a1 = np.array([27.5, 14.1])\n",
    "a2 = np.random.uniform(low=3, high=7.5, size=(13))\n",
    "a2 = np.sort(a2)[::-1]\n",
    "a3 = np.random.uniform(low=1, high=3.4, size=(15))\n",
    "a4 = np.random.uniform(low=0.3, high=1.5, size=(10))\n",
    "a5 = np.random.uniform(low=0.3, high=1, size=(20))\n",
    "a = np.concatenate([a1, a2, a3, a4, a5])\n",
    "a = torch.tensor(a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([60])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = np.concatenate([a1, a2, a3, a4, a5])\n",
    "# a = torch.tensor(a)\n",
    "a.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}